{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cd21d6-578f-46a4-85ee-1b83fe5bcc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats import entropy\n",
    "from getData import *\n",
    "from trainer import *\n",
    "from getModel import *\n",
    "#import torchprofile\n",
    "\n",
    "import time\n",
    "# Seed for reproducibility\n",
    "SEED = 25\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796dbbc-fb81-4a73-8bc9-8d4afc2132d4",
   "metadata": {},
   "source": [
    "# **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c69ff39-06cf-466f-8774-f24f00d53f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Training\\\\Fire', 'Training\\\\No_Fire']\n",
      "['Test\\\\Fire', 'Test\\\\No_Fire']\n"
     ]
    }
   ],
   "source": [
    "dataset = TrainValDataset()\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size= 32, shuffle = True, num_workers= 0)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size= 32, shuffle = False, num_workers= 0)\n",
    "\n",
    "test_dataset = TestDataset()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size= 32, shuffle = False, num_workers= 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bcb05d-20f3-4e79-aa5a-23bce3ff7458",
   "metadata": {},
   "source": [
    "# **Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fdad25-ef1b-4749-a29b-c9f98247ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cc4341-ec5a-4608-baf7-0996f957eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blNet = blModel().to(device)\n",
    "optimizer_bl = optim.Adam(blNet.parameters(), lr=1e-3)\n",
    "scheduler = None\n",
    "criterion_bl = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a846a6e-2f72-4646-9d44-e760088c1c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 --> trainLoss: 0.049, trainAcc: 0.984, validLoss: 0.028, validAcc: 0.989\n",
      "Model Saved!\n",
      "epoch 2 --> trainLoss: 0.017, trainAcc: 0.994, validLoss: 0.021, validAcc: 0.994\n",
      "Model Saved!\n",
      "epoch 3 --> trainLoss: 0.012, trainAcc: 0.996, validLoss: 0.013, validAcc: 0.996\n",
      "Model Saved!\n",
      "epoch 4 --> trainLoss: 0.012, trainAcc: 0.997, validLoss: 0.006, validAcc: 0.999\n",
      "Model Saved!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m bl_titleToday \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Models/best_bl_0319.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m BL \u001b[38;5;241m=\u001b[39m blHandler(blNet, criterion_bl, optimizer_bl, device\u001b[38;5;241m=\u001b[39mdevice, scheduler\u001b[38;5;241m=\u001b[39mscheduler, num_epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS, bestPath\u001b[38;5;241m=\u001b[39mbl_titleToday)\n\u001b[1;32m----> 3\u001b[0m blNet, blHistory \u001b[38;5;241m=\u001b[39m \u001b[43mBL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\ENDG-511-Project\\trainer.py:50\u001b[0m, in \u001b[0;36mblHandler.train\u001b[1;34m(self, tLoader, vLoader)\u001b[0m\n\u001b[0;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output, labels)\n\u001b[0;32m     49\u001b[0m totalLoss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 50\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mround(output)\n\u001b[0;32m     53\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), predicted\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\endg511\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\endg511\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bl_titleToday = \"./Models/best_bl_0319.pth\"\n",
    "BL = blHandler(blNet, criterion_bl, optimizer_bl, device=device, scheduler=scheduler, num_epochs=NUM_EPOCHS, bestPath=bl_titleToday)\n",
    "blNet, blHistory = BL.train(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611fc1af-4768-4040-9605-2afde52558f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_titleToday = \"./Models/best_bl_0319.pth\"\n",
    "blNet.load_state_dict(torch.load(\"./Models/best_bl_0319.pth\"))\n",
    "BL = blHandler(blNet, criterion_bl, optimizer_bl, device=device, scheduler=scheduler, num_epochs=NUM_EPOCHS, bestPath=bl_titleToday)\n",
    "predicted, acc = BL.infer(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11175ac-c814-421a-953e-db5ee9247cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f67556-424d-4255-903b-832fb43031d6",
   "metadata": {},
   "source": [
    "# **EEM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad411f8b-cffb-4cd2-9946-0740e36470cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad62411-8cdb-4e4e-b16e-a3dc4ce5e177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
