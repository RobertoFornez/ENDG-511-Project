{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2A3Do1RO6JN0QM9JATiDr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# model_train notebook\n",
        "\n",
        "The model_training notebook uses the 7th dataset file of the IEEE FLAME dataset to traing a classification model able to identify aerial views of fire and no fire.\n",
        "\n",
        "https://ieee-dataport.org/open-access/flame-dataset-aerial-imagery-pile-burn-detection-using-drones-uavs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x1lbbQNNOt5C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D8tcN8tgNjT2"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "import os.path\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model parameters\n",
        "\n",
        "# Add random transformations to training images to slow down overfitting due to\n",
        "# smaller dataset\n",
        "data_augmentation = keras.Sequential(\n",
        "        [\n",
        "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "new_size = {'width': 256, 'height': 256}\n",
        "Config_classification = {'batch_size': 32, 'Save_Model': True, 'Epochs': 40,\n",
        "                         'TrainingPlot': True}\n",
        "\n",
        "# Define size of images, batch size, and # of epochs\n",
        "image_size = (new_size.get('width'), new_size.get('height'))\n",
        "batch_size = Config_classification.get('batch_size')\n",
        "save_model_flag = Config_classification.get('Save_Model')\n",
        "epochs = Config_classification.get('Epochs')\n",
        "\n",
        "# Create metrics for visuals\n",
        "METRICS = [\n",
        "    keras.metrics.TruePositives(name='tp'),\n",
        "    keras.metrics.FalsePositives(name='fp'),\n",
        "    keras.metrics.TrueNegatives(name='tn'),\n",
        "    keras.metrics.FalseNegatives(name='fn'),\n",
        "    keras.metrics.Accuracy(name='accuracy'),\n",
        "    keras.metrics.BinaryAccuracy(name='bin_accuracy'),\n",
        "    keras.metrics.Precision(name='precision'),\n",
        "    keras.metrics.Recall(name='recall'),\n",
        "    keras.metrics.AUC(name='auc')\n",
        "]"
      ],
      "metadata": {
        "id": "Fwo9J796Uape"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a DNN model based on Keras and Tensorflow as a backend. At first, the directory of Fire and Non_Fire images should be defined for the model, then the model is defined, compiled and fitted over the training and validation set. At the end, the models is saved based on the *.h5 parameters and weights. Training accuracy and loss are demonstrated at the end of this function.\n",
        "\n",
        "https://keras.io/examples/vision/image_classification_from_scratch/"
      ],
      "metadata": {
        "id": "QUq2yKFrhphP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_fire = 'Frames/Training/Fire/'\n",
        "dir_no_fire = 'Frames/Training/No_Fire/'"
      ],
      "metadata": {
        "id": "8UU8xSpxZsr5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}