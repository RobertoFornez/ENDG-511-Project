{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1lbbQNNOt5C"
   },
   "source": [
    "# model_train notebook\n",
    "\n",
    "The model_training notebook uses the 7th dataset file of the IEEE FLAME dataset to traing a classification model able to identify aerial views of fire and no fire.\n",
    "\n",
    "https://ieee-dataport.org/open-access/flame-dataset-aerial-imagery-pile-burn-detection-using-drones-uavs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D8tcN8tgNjT2"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8MbOqkt8gmI",
    "outputId": "d5ff4f09-9a24-4bac-ffa5-56431d87fa8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Fwo9J796Uape"
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "\n",
    "# Add random transformations to training images to slow down overfitting due to\n",
    "# smaller dataset\n",
    "data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "new_size = {'width': 256, 'height': 256}\n",
    "Config_classification = {'batch_size': 32, 'Save_Model': True, 'Epochs': 5,\n",
    "                         'TrainingPlot': True}\n",
    "\n",
    "# Define size of images, batch size, and # of epochs\n",
    "image_size = (new_size.get('width'), new_size.get('height'))\n",
    "batch_size = Config_classification.get('batch_size')\n",
    "save_model_flag = Config_classification.get('Save_Model')\n",
    "epochs = Config_classification.get('Epochs')\n",
    "\n",
    "# Create metrics for visuals\n",
    "METRICS = [\n",
    "    keras.metrics.TruePositives(name='tp'),\n",
    "    keras.metrics.FalsePositives(name='fp'),\n",
    "    keras.metrics.TrueNegatives(name='tn'),\n",
    "    keras.metrics.FalseNegatives(name='fn'),\n",
    "    keras.metrics.Accuracy(name='accuracy'),\n",
    "    keras.metrics.BinaryAccuracy(name='bin_accuracy'),\n",
    "    keras.metrics.Precision(name='precision'),\n",
    "    keras.metrics.Recall(name='recall'),\n",
    "    keras.metrics.AUC(name='auc')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUq2yKFrhphP"
   },
   "source": [
    "Train a DNN model based on Keras and Tensorflow as a backend. At first, the directory of Fire and Non_Fire images should be defined for the model, then the model is defined, compiled and fitted over the training and validation set. At the end, the models is saved based on the *.h5 parameters and weights. Training accuracy and loss are demonstrated at the end of this function.\n",
    "\n",
    "https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8UU8xSpxZsr5"
   },
   "outputs": [],
   "source": [
    "# Load dataset images\n",
    "dir_fire = 'gdrive/MyDrive/Colab Notebooks/Frames/Training/Fire/'\n",
    "dir_no_fire = 'gdrive/MyDrive/Colab Notebooks/Frames/Training/No_Fire/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-V6rX3d8cGo",
    "outputId": "3b424017-3628-4e52-a973-5252e9fe1cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39624 files belonging to 2 classes.\n",
      "Using 31700 files for training.\n",
      "Found 39624 files belonging to 2 classes.\n",
      "Using 7924 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation datasets\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"gdrive/MyDrive/Colab Notebooks/Frames/Training\", validation_split=0.2, subset=\"training\", seed=1337, image_size=image_size,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"gdrive/MyDrive/Colab Notebooks/Frames/Training\", validation_split=0.2, subset=\"validation\", seed=1337, image_size=image_size,\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1fXorIw8cGp"
   },
   "outputs": [],
   "source": [
    "# Function to make Keras model\n",
    "def make_model_keras(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    This function define the DNN Model based on the Keras example.\n",
    "    :param input_shape: The requested size of the image\n",
    "    :param num_classes: In this classification problem, there are two classes: 1) Fire and 2) Non_Fire.\n",
    "    :return: The built model is returned\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # x = data_augmentation(inputs)  # 1) First option\n",
    "    x = inputs  # 2) Second option\n",
    "\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    # x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.Conv2D(8, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x\n",
    "\n",
    "    # for size in [128, 256, 512, 728]:\n",
    "    for size in [8]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(previous_block_activation)\n",
    "\n",
    "        x = layers.add([x, residual])\n",
    "        previous_block_activation = x\n",
    "    x = layers.SeparableConv2D(8, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs, name=\"model_fire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCCyR5v98cGq",
    "outputId": "5a5f76ce-7b16-4d98-933b-af48272c03e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = make_model_keras(input_shape=image_size + (3,), num_classes=2)\n",
    "model.save('untrained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6mnt7UEeMr9",
    "outputId": "6e09490e-18b0-435d-db57-b4c09c679bcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('untrained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWWiLFxQ8cGq",
    "outputId": "17225b30-0d04-4e68-cb8a-e2aab0c366c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "269/991 [=======>......................] - ETA: 1:16:28 - loss: 0.3927 - accuracy: 0.8296"
     ]
    }
   ],
   "source": [
    "# Compile and train model\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "res_fire = model.fit(train_ds, epochs=epochs, validation_data=val_ds, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
